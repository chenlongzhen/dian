{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%pylab inline\n",
    "#%matplotlib inline\n",
    "    \n",
    "import pywt\n",
    "import numpy as np\n",
    "import seaborn\n",
    "from statsmodels.robust import mad\n",
    "import matplotlib.pyplot as plt  \n",
    "import sys\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from dateutil.parser import parse\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def waveletSmooth( x, wavelet=\"db4\", level=1, title=None ):\n",
    "    ''' smooth denoise'''\n",
    "    # calculate the wavelet coefficients\n",
    "    coeff = pywt.wavedec( x, wavelet, mode=\"per\" )\n",
    "    # calculate a threshold\n",
    "    sigma = mad( coeff[-level] )\n",
    "    # changing this threshold also changes the behavior,\n",
    "    # but I have not played with this very much\n",
    "    uthresh = sigma * np.sqrt( 2*np.log( len( x ) ) )\n",
    "    coeff[1:] = ( pywt.threshold( i, value=uthresh, mode=\"soft\" ) for i in coeff[1:] )\n",
    "    # reconstruct the signal using the thresholded coefficients\n",
    "    y = pywt.waverec( coeff, wavelet, mode=\"per\" )\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_date</th>\n",
       "      <th>user_id</th>\n",
       "      <th>power_consumption</th>\n",
       "      <th>week</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1135</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>570</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>3418</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>3968</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>3986</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  record_date  user_id  power_consumption  week  month  day  year\n",
       "0  2015-01-01        1               1135     3      1    1  2015\n",
       "1  2015-01-02        1                570     4      1    2  2015\n",
       "2  2015-01-03        1               3418     5      1    3  2015\n",
       "3  2015-01-04        1               3968     6      1    4  2015\n",
       "4  2015-01-05        1               3986     0      1    5  2015"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def read(filePath):\n",
    "    '''\n",
    "    read data 2 dict\n",
    "    '''\n",
    "    #!!!\n",
    "    data = pd.read_csv(filePath)\n",
    "    data['record_date'] = data['record_date'].apply(lambda x:parse(str(x)).strftime('%Y-%m-%d'))\n",
    "    data['week'] = data['record_date'].apply(lambda x:datetime.datetime.strptime(x,'%Y-%m-%d').weekday())\n",
    "    data['month'] = data['record_date'].apply(lambda x:datetime.datetime.strptime(x,'%Y-%m-%d').month)\n",
    "    data['day'] = data['record_date'].apply(lambda x:datetime.datetime.strptime(x,'%Y-%m-%d').day)\n",
    "    data['year'] = data['record_date'].apply(lambda x:datetime.datetime.strptime(x,'%Y-%m-%d').year)\n",
    "    data.to_csv(\"./data/dataRead.csv\",index=False)\n",
    "    \n",
    "    return data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1454/1454 [02:49<00:00,  9.08it/s]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "pdf = PdfPages('./data/originyearly.pdf')\n",
    "\n",
    "def draw(data):\n",
    "    '''\n",
    "    read data 2 dict\n",
    "    '''\n",
    "    data2 = data.groupby('user_id')\n",
    "    for key,name in tqdm(data2):\n",
    "        fig = plt.figure(1,figsize=(20,10))\n",
    "        timeSerie = pd.Series(data=name['power_consumption'].values,index=name['record_date'])\n",
    "        ax = plt.plot(timeSerie.values[:365],'b')\n",
    "        ax = plt.plot(timeSerie.values[365:],'r')\n",
    "        pdf.savefig()\n",
    "        plt.close()\n",
    "    pdf.close()\n",
    "    return data\n",
    "\n",
    "data = draw(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1454 [00:00<?, ?it/s]/Users/clz/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:7: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "/Users/clz/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "100%|██████████| 1454/1454 [34:33<00:00,  2.58s/it] \n"
     ]
    }
   ],
   "source": [
    "# 归一化保存\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "scalerDic={} # store scaler class\n",
    "def scaleProcess(key,data):\n",
    "    robust_scaler = RobustScaler(with_centering=True, with_scaling=True, quantile_range=(10.0, 90.0), copy=True)\n",
    "    data['power_consumption_scale'] = robust_scaler.fit_transform(data['power_consumption'].reshape(-1,1))\n",
    "    scalerDic[key] = robust_scaler\n",
    "    return data\n",
    "\n",
    "scaleList=[] # userid scaled matrix\n",
    "def scaleData(data):\n",
    "    '''\n",
    "    read data 2 dict\n",
    "    '''\n",
    "    pdf = PdfPages('./data/scale.pdf')\n",
    "    \n",
    "    #draw\n",
    "    data2 = data.groupby('user_id')\n",
    "    for key,truck in tqdm(data2): \n",
    "        scaleData = scaleProcess(key,truck)\n",
    "        scaleList.append(scaleData)\n",
    "        \n",
    "        fig = plt.figure(1,figsize=(20,10))\n",
    "        timeSerie2 = pd.Series(data=scaleData['power_consumption_scale'].values,index=scaleData['record_date'])\n",
    "        ax = plt.plot(timeSerie2.values,'r')\n",
    "        pdf.savefig()\n",
    "        plt.close()\n",
    "    pdf.close()\n",
    " \n",
    "scaleData(data)\n",
    "\n",
    "# scaleList  save \n",
    "import pickle\n",
    "with open('./data/scaleList', 'wb') as fp:\n",
    "    pickle.dump(scaleList, fp)\n",
    "    \n",
    "with open('./data/scalerDic', 'wb') as fp:\n",
    "    pickle.dump(scalerDic, fp)   \n",
    "\n",
    "#check\n",
    "#datax = scalerDic[2].inverse_transform(scaleList[1]['power_consumption_scale'])\n",
    "#plt.plot(datax)\n",
    "#plt.plot(scaleList[1]['power_consumption'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read scale\n",
    "with open ('./data/scaleList', 'rb') as fp:\n",
    "    scaleList = pickle.load(fp)\n",
    "    \n",
    "with open ('./data/scalerDic', 'rb') as fp:\n",
    "    scalerDic = pickle.load(fp)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_date</th>\n",
       "      <th>user_id</th>\n",
       "      <th>power_consumption</th>\n",
       "      <th>week</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>year</th>\n",
       "      <th>power_consumption_scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1135</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.057134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>570</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.194012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>3418</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "      <td>4.544760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>3968</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>5.384968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>3986</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>5.412466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  record_date  user_id  power_consumption  week  month  day  year  \\\n",
       "0  2015-01-01        1               1135     3      1    1  2015   \n",
       "1  2015-01-02        1                570     4      1    2  2015   \n",
       "2  2015-01-03        1               3418     5      1    3  2015   \n",
       "3  2015-01-04        1               3968     6      1    4  2015   \n",
       "4  2015-01-05        1               3986     0      1    5  2015   \n",
       "\n",
       "   power_consumption_scale  \n",
       "0                 1.057134  \n",
       "1                 0.194012  \n",
       "2                 4.544760  \n",
       "3                 5.384968  \n",
       "4                 5.412466  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaleList[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1454 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-a6e6119e8b89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moriginTrainXList\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moriginTrainYList\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moriginTestXList\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moriginTestYList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0moriginTrainXList\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moriginTrainYList\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moriginTestXList\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moriginTestYList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-110-a6e6119e8b89>\u001b[0m in \u001b[0;36mgetTrain\u001b[0;34m(scaleList, testMonth)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0moriginTestYList\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0muserData\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaleList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mtrainX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muserData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonth\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtestMonth\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0muserData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2015\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'power_consumption'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'week'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mtrainY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muserData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonth\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtestMonth\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0muserData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2016\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'power_consumption'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'week'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtestX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muserData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtestMonth\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0muserData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2015\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'power_consumption'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'week'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clz/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    915\u001b[0m         raise ValueError(\"The truth value of a {0} is ambiguous. \"\n\u001b[1;32m    916\u001b[0m                          \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m                          .format(self.__class__.__name__))\n\u001b[0m\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[0m__bool__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "# 用去年的预测今年的数据 按照日期对应 1-7月训练 8月validation \n",
    "def getTrain(scaleList=scaleList,testMonth=8):\n",
    "    originTrainXList = []\n",
    "    originTrainYList = []\n",
    "    originTestXList=[]\n",
    "    originTestYList=[]\n",
    "    for userData in tqdm(scaleList):\n",
    "        trainX = userData[userData.month < testMonth & userData.year == 2015][['power_consumption'],['week']]\n",
    "        trainY = userData[userData.month < testMonth & userData.year == 2016][['power_consumption'],['week']]\n",
    "        testX = userData[userData.month == testMonth & userData.year == 2015][['power_consumption'],['week']]\n",
    "        testY = userData[userData.month == testMonth & userData.year == 2016][['power_consumption'],['week']]\n",
    "        originTrainXList.append(trainX)\n",
    "        originTrainYList.append(trainY)\n",
    "        originTestXList.append(testX)\n",
    "        originTestYList.append(testY)\n",
    "        \n",
    "    with open('./data/originTrainXList', 'wb') as fp:\n",
    "        pickle.dump(originTrainXList, fp)\n",
    "    \n",
    "    with open('./data/originTrainYList', 'wb') as fp:\n",
    "        pickle.dump(originTrainYList, fp)\n",
    "        \n",
    "    with open('./data/originTestXList', 'wb') as fp: \n",
    "        pickle.dump(originTestXList, fp)\n",
    "        \n",
    "    with open('./data/originTestYList', 'wb') as fp:\n",
    "        pickle.dump(originTestYList, fp)\n",
    " \n",
    "        \n",
    "    return originTrainXList,originTrainYList,originTestXList,originTestYList\n",
    "originTrainXList,originTrainYList,originTestXList,originTestYList = getTrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LSTM for international airline passengers problem with window regression framing\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back-1):\n",
    "\t\ta = dataset[i:(i+look_back), 0]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back, 0])\n",
    "\treturn numpy.array(dataX), numpy.array(dataY)\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# load the dataset\n",
    "dataframe = read_csv('international-airline-passengers.csv', usecols=[1], engine='python', skipfooter=3)\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')\n",
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "# split into train and test sets\n",
    "train_size = int(len(dataset) * 0.67)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "# reshape into X=t and Y=t+1\n",
    "look_back = 3\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)\n",
    "# make predictions\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "# invert predictions\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "# shift train predictions for plotting\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sumAll(data):\n",
    "    '''sum by day'''\n",
    "    dataSum = pd.DataFrame()\n",
    "     \n",
    "  \n",
    "    dataSum['sum_consumption'] = data.groupby('record_date')['smooth'].sum() \n",
    "\n",
    "    dataSum['record_date'] = dataSum.index\n",
    "    dataSum['week'] = dataSum['record_date'].apply(lambda x:datetime.datetime.strptime(x,'%Y-%m-%d').weekday())\n",
    "    dataSum['month'] = dataSum['record_date'].apply(lambda x:datetime.datetime.strptime(x,'%Y-%m-%d').month)\n",
    "    dataSum['day'] = dataSum['record_date'].apply(lambda x:datetime.datetime.strptime(x,'%Y-%m-%d').day)\n",
    "  \n",
    "    return dataSum\n",
    "    \n",
    "#  1.read and processdata   \n",
    "dataRead = read(\"./data/Tianchi_power.csv\")\n",
    "dataRead.to_csv(\"./data/dataRead.csv\",index=False)\n",
    "plt.plot(dataRead[dataRead==1000]['power_consumption'])\n",
    "print dataRead.head() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
